{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6b1c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_inputs(report_dir, files, truth_dir=None, mode='train'):\n",
    "    \n",
    "    data = pd.read_csv(os.path.join(report_dir, files[0]+'.csv'), sep=',')[['id','proba']]\n",
    "    \n",
    "    for i in range(len(files)-1):\n",
    "        join = pd.read_csv(os.path.join(report_dir, files[i+1]+'.csv'), sep=',')['proba']\n",
    "        data = pd.concat([data, join], axis=1)\n",
    "        \n",
    "    if mode == 'train':\n",
    "        truth = pd.read_json(truth_dir, orient='records', lines=True)\n",
    "        label = truth['label']\n",
    "        data = pd.concat([data, label], axis=1)\n",
    "\n",
    "    elif mode == 'test':\n",
    "        join = data['id'].astype(\"string\").str.cat(['jpg']*data.shape[0], sep='.')\n",
    "        \n",
    "    data.drop(columns=['id'], inplace=True)\n",
    "        \n",
    "    return data, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f798298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class mamiDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data, mode='train'):\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "            self.inp = data.iloc[:,:-1].values\n",
    "            self.oup = data.iloc[:,-1].values.reshape(-1,1)\n",
    "        else:\n",
    "            self.inp = data.values\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.inp)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            inpt  = torch.Tensor(self.inp[idx])\n",
    "            oupt  = torch.Tensor(self.oup[idx])\n",
    "            return {'inp': inpt,\n",
    "                    'oup': oupt}\n",
    "        else:\n",
    "            inpt = torch.Tensor(self.inp[idx])\n",
    "            return {'inp': inpt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b62143b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=7):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.fc1 = nn.Linear(self.input_dim, 16)\n",
    "        self.b1 = nn.BatchNorm1d(16)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.b2 = nn.BatchNorm1d(8)\n",
    "        self.fc3 = nn.Linear(8,2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.b1(torch.sigmoid(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.b2(torch.sigmoid(x))\n",
    "        x = self.fc3(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "# class Network(nn.Module):\n",
    "    \n",
    "#     def __init__(self, input_dim=7):\n",
    "#         super().__init__()\n",
    "#         self.input_dim = input_dim\n",
    "#         self.fc1 = nn.Linear(self.input_dim, 8)\n",
    "#         self.b1 = nn.BatchNorm1d(8)\n",
    "#         self.fc2 = nn.Linear(8,2)\n",
    "\n",
    "#     def forward(self,x):\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.b1(torch.sigmoid(x))\n",
    "#         x = self.fc2(x)\n",
    "#         x = F.softmax(x, dim=1)\n",
    "#         return x\n",
    "\n",
    "# F.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d87468ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x, y, optimizer, criterion):\n",
    "    \n",
    "    model.zero_grad()\n",
    "    output = model(x)\n",
    "    y = y.to(torch.int64)\n",
    "    loss = criterion(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97aef937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "def scoreA(labels, truth):\n",
    "        \n",
    "    matrix = metrics.confusion_matrix(truth, labels)\n",
    "\n",
    "    #positive label\n",
    "    if matrix[0][0] == 0:\n",
    "        pos_precision = 0.0\n",
    "        pos_recall = 0.0\n",
    "    else:\n",
    "        pos_precision = matrix[0][0]*1.0 / (matrix[0][0] + matrix[0][1])\n",
    "        pos_recall = matrix[0][0]*1.0 / (matrix[0][0] + matrix[1][0])\n",
    "\n",
    "    if (pos_precision + pos_recall) != 0:\n",
    "        pos_F1 = 2 * (pos_precision * pos_recall)*1.0 / (pos_precision + pos_recall)\n",
    "    else:\n",
    "        pos_F1 = 0\n",
    "\n",
    "    #negative label\n",
    "    neg_matrix = [[matrix[1][1], matrix[1][0]], [matrix[0][1], matrix[0][0]]]\n",
    "\n",
    "    if neg_matrix[0][0] == 0:\n",
    "        neg_precision = 0.0\n",
    "        neg_recall = 0.0\n",
    "    else:\n",
    "        neg_precision = neg_matrix[0][0]*1.0 / (neg_matrix[0][0] + neg_matrix[0][1])\n",
    "        neg_recall = neg_matrix[0][0]*1.0 / (neg_matrix[0][0] + neg_matrix[1][0])\n",
    "\n",
    "    if (neg_precision + neg_recall) != 0:\n",
    "        neg_F1 = 2 * (neg_precision * neg_recall) / (neg_precision + neg_recall)\n",
    "    else:\n",
    "        neg_F1 = 0\n",
    "\n",
    "    f1 = (pos_F1 + neg_F1) / 2\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed36eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5a01636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def training_loop(dataloader, net, optm, criterion, device):\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        for bidx, batch in tqdm(enumerate(dataloader)):\n",
    "            x_train, y_train = batch['inp'], batch['oup']\n",
    "            y_train = y_train.squeeze(axis=1)\n",
    "            x_train = x_train.view(-1,INPUT_DIM)\n",
    "            \n",
    "            loss, predictions = train(net, x_train, y_train, optm, criterion)\n",
    "            predictions = predictions.argmax(dim=1)\n",
    "            \n",
    "            for idx, i in enumerate(predictions):\n",
    "                if i == y_train[idx]:\n",
    "                    correct += 1\n",
    "            epoch_loss += loss\n",
    "\n",
    "\n",
    "        print('\\033[30m'+'Epoch {} scoreA : {}'.format(epoch+1, scoreA(predictions, y_train)))\n",
    "        print('\\033[30m'+'Epoch {} Loss : {}'.format(epoch+1, epoch_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baf0f70",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "165eecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 5\n",
    "INPUT_DIM = 3\n",
    "mi_file = ['./save/new_mami/misogynous_concat_bert', './save/new_mami/misogynous_mmf_transformer', './save/new_mami/misogynous_visual_bert']\n",
    "sh_file = ['./save/new_mami/shaming_late_fusion', './save/new_mami/shaming_mmbt', './save/new_mami/shaming_visual_bert']\n",
    "st_file = ['./save/new_mami/stereotype_late_fusion', './save/mami/stereotype_mmf_transformer', './save/mami/stereotype_visual_bert']\n",
    "ob_file = ['./save/new_mami/objectification_concat_bert', './save/new_mami/objectification_mmf_transformer', './save/mami/objectification_vilbert']\n",
    "vi_file = ['./save/new_mami/violence_concat_bert', './save/mami/violence_mmf_transformer', './save/mami/violence_vilbert']\n",
    "files = [mi_file, sh_file, st_file, ob_file, vi_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e4bda65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:00, 533.23it/s]\n",
      "63it [00:00, 586.43it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30mEpoch 1 scoreA : 0.873015873015873\n",
      "\u001b[30mEpoch 1 Loss : 48.52399444580078\n",
      "\u001b[30mEpoch 2 scoreA : 0.7499999999999999\n",
      "\u001b[30mEpoch 2 Loss : 32.802555084228516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:00, 603.34it/s]\n",
      "63it [00:00, 603.65it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30mEpoch 3 scoreA : 0.7499999999999999\n",
      "\u001b[30mEpoch 3 Loss : 30.8625431060791\n",
      "\u001b[30mEpoch 4 scoreA : 0.7499999999999999\n",
      "\u001b[30mEpoch 4 Loss : 30.33580780029297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:00, 602.33it/s]\n",
      "63it [00:00, 602.11it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30mEpoch 5 scoreA : 0.7499999999999999\n",
      "\u001b[30mEpoch 5 Loss : 30.04253387451172\n",
      "\u001b[34mmisogynous\t0.8129376374529184\t0.33035714285714285\n",
      "\u001b[30mEpoch 1 scoreA : 0.5636363636363637\n",
      "\u001b[30mEpoch 1 Loss : 43.27499008178711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:00, 586.32it/s]\n",
      "63it [00:00, 590.45it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30mEpoch 2 scoreA : 0.7948717948717948\n",
      "\u001b[30mEpoch 2 Loss : 36.21982192993164\n",
      "\u001b[30mEpoch 3 scoreA : 0.7948717948717948\n",
      "\u001b[30mEpoch 3 Loss : 33.342315673828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:00, 594.19it/s]\n",
      "63it [00:00, 591.85it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30mEpoch 4 scoreA : 0.7948717948717948\n",
      "\u001b[30mEpoch 4 Loss : 32.01633834838867\n",
      "\u001b[30mEpoch 5 scoreA : 0.7948717948717948\n",
      "\u001b[30mEpoch 5 Loss : 31.18838882446289\n",
      "\u001b[34mshaming\t0.7001789254799555\t0.10714285714285712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:00, 601.67it/s]\n",
      "63it [00:00, 597.37it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30mEpoch 1 scoreA : 0.7333333333333334\n",
      "\u001b[30mEpoch 1 Loss : 43.07279586791992\n",
      "\u001b[30mEpoch 2 scoreA : 0.7333333333333334\n",
      "\u001b[30mEpoch 2 Loss : 36.22616195678711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:00, 605.15it/s]\n",
      "63it [00:00, 604.00it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30mEpoch 3 scoreA : 0.7333333333333334\n",
      "\u001b[30mEpoch 3 Loss : 35.13361358642578\n",
      "\u001b[30mEpoch 4 scoreA : 0.7333333333333334\n",
      "\u001b[30mEpoch 4 Loss : 34.637779235839844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:00, 593.29it/s]\n",
      "63it [00:00, 600.96it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30mEpoch 5 scoreA : 0.5636363636363636\n",
      "\u001b[30mEpoch 5 Loss : 34.27289962768555\n",
      "\u001b[34mstereotype\t0.6878458526064871\t0.33793625271919037\n",
      "\u001b[30mEpoch 1 scoreA : 0.42857142857142855\n",
      "\u001b[30mEpoch 1 Loss : 46.51033401489258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:00, 601.73it/s]\n",
      "63it [00:00, 602.85it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30mEpoch 2 scoreA : 0.42857142857142855\n",
      "\u001b[30mEpoch 2 Loss : 34.715415954589844\n",
      "\u001b[30mEpoch 3 scoreA : 0.4666666666666667\n",
      "\u001b[30mEpoch 3 Loss : 32.63880920410156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:00, 596.72it/s]\n",
      "63it [00:00, 604.32it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30mEpoch 4 scoreA : 0.4666666666666667\n",
      "\u001b[30mEpoch 4 Loss : 31.75556755065918\n",
      "\u001b[30mEpoch 5 scoreA : 0.4666666666666667\n",
      "\u001b[30mEpoch 5 Loss : 31.20968246459961\n",
      "\u001b[34mobjectification\t0.8609225471042088\t0.41486834537771006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:00, 592.20it/s]\n",
      "63it [00:00, 607.22it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30mEpoch 1 scoreA : 0.6666666666666666\n",
      "\u001b[30mEpoch 1 Loss : 40.74103927612305\n",
      "\u001b[30mEpoch 2 scoreA : 0.6666666666666666\n",
      "\u001b[30mEpoch 2 Loss : 35.11079788208008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:00, 604.04it/s]\n",
      "63it [00:00, 605.24it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30mEpoch 3 scoreA : 0.7948717948717948\n",
      "\u001b[30mEpoch 3 Loss : 32.44279098510742\n",
      "\u001b[30mEpoch 4 scoreA : 0.7948717948717948\n",
      "\u001b[30mEpoch 4 Loss : 30.688753128051758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:00, 602.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30mEpoch 5 scoreA : 1.0\n",
      "\u001b[30mEpoch 5 Loss : 29.453937530517578\n",
      "\u001b[34mviolence\t0.705232129697863\t0.5268817204301076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "truth_list = ['/home/taochen/mmf/data/datasets/mami/defaults/annotations/val_misogynous.jsonl',\n",
    "             '/home/taochen/mmf/data/datasets/mami/defaults/annotations/val_shaming.jsonl',\n",
    "             '/home/taochen/mmf/data/datasets/mami/defaults/annotations/val_stereotype.jsonl',\n",
    "             '/home/taochen/mmf/data/datasets/mami/defaults/annotations/val_objectification.jsonl',\n",
    "             '/home/taochen/mmf/data/datasets/mami/defaults/annotations/val_violence.jsonl']\n",
    "col_names = ['misogynous', 'shaming', 'stereotype', 'objectification', 'violence']\n",
    "nets = []\n",
    "\n",
    "gpu = 0\n",
    "device = torch.device(gpu if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(gpu)\n",
    "    \n",
    "for idx in range(len(files)):\n",
    "    truth_dir = truth_list[idx]\n",
    "    data, comp = concat_inputs(report_dir='', files=files[idx], truth_dir=truth_dir)\n",
    "    \n",
    "    data_train = mamiDataset(data=data)\n",
    "    data_test = torch.tensor(data.iloc[800:,:-1].values).to(torch.float32)\n",
    "    dataloader = DataLoader(dataset = data_train, batch_size = BATCH_SIZE, shuffle = False)\n",
    "    \n",
    "    net = Network(INPUT_DIM)\n",
    "    optm = Adam(net.parameters(), lr = 0.001)\n",
    "    training_loop(dataloader, net, optm, criterion, device)\n",
    "    res = net(data_test).argmax(axis=1)\n",
    "    \n",
    "    truth = pd.read_json(truth_dir, orient='records', lines=True)[800:]\n",
    "    truth = truth['label']\n",
    "    torch.tensor(truth.values)\n",
    "    \n",
    "    comp = comp[800:]\n",
    "    comp = torch.tensor((comp > 0.5).values).to(torch.int64)\n",
    "    \n",
    "    print('\\033[34m' + col_names[idx]+ '\\t' + str(scoreA(res, truth))+ '\\t' + str(scoreA(comp, truth)))\n",
    "    nets.append(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce0152b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_file = ['./save/new_mami_submission/misogynous_concat_bert', './save/new_mami_submission/misogynous_mmf_transformer', './save/new_mami_submission/misogynous_visual_bert']\n",
    "sh_file = ['./save/new_mami_submission/shaming_late_fusion', './save/new_mami_submission/shaming_mmbt', './save/new_mami_submission/shaming_visual_bert']\n",
    "st_file = ['./save/new_mami_submission/stereotype_late_fusion', './save/mami_submission/stereotype_mmf_transformer', './save/mami_submission/stereotype_visual_bert']\n",
    "ob_file = ['./save/new_mami_submission/objectification_concat_bert', './save/new_mami_submission/objectification_mmf_transformer', './save/mami_submission/objectification_vilbert']\n",
    "vi_file = ['./save/new_mami_submission/violence_concat_bert', './save/mami_submission/violence_mmf_transformer', './save/mami_submission/violence_vilbert']\n",
    "files = [mi_file, sh_file, st_file, ob_file, vi_file]\n",
    "\n",
    "for idx in range(len(files)):\n",
    "    \n",
    "    data, ids = concat_inputs(report_dir='', files=files[idx], mode='test')\n",
    "        \n",
    "    net = nets[idx]\n",
    "    logits = net(torch.tensor(data.values, dtype=torch.float32))\n",
    "    res = logits.argmax(axis=1).to(torch.int64).unsqueeze(axis=1)\n",
    "\n",
    "    if idx == 0:\n",
    "        submission = res\n",
    "    else:\n",
    "        submission = torch.cat((submission, res), dim=1)\n",
    "\n",
    "out_path = 'answer_nn.txt'\n",
    "submission = pd.DataFrame(submission.numpy())\n",
    "submission = pd.concat([pd.DataFrame(ids), submission], axis=1)\n",
    "\n",
    "# # fix misogynous columns\n",
    "# temp = submission[submission.iloc[:,1] == 0]\n",
    "# temp = temp.iloc[:,2:].sum(axis=1) > 1\n",
    "# temp = temp.loc[temp == True].index.to_list()\n",
    "# submission.iloc[temp,1] = 1\n",
    "\n",
    "# # fix other four columns\n",
    "# filter_ = submission.iloc[:,1] == 0\n",
    "# submission[filter_] = submission[filter_].replace(1, 0)\n",
    "submission.to_csv(out_path, header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef96fd84",
   "metadata": {},
   "source": [
    "## Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c889d27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_file = ['./save/new_mami_submission/misogynous_concat_bert', './save/new_mami_submission/misogynous_mmf_transformer', './save/new_mami_submission/misogynous_visual_bert']\n",
    "sh_file = ['./save/new_mami_submission/shaming_late_fusion', './save/new_mami_submission/shaming_mmbt', './save/new_mami_submission/shaming_visual_bert']\n",
    "st_file = ['./save/new_mami_submission/stereotype_late_fusion', './save/mami_submission/stereotype_mmf_transformer', './save/mami_submission/stereotype_visual_bert']\n",
    "ob_file = ['./save/new_mami_submission/objectification_concat_bert', './save/new_mami_submission/objectification_mmf_transformer', './save/mami_submission/objectification_vilbert']\n",
    "vi_file = ['./save/new_mami_submission/violence_concat_bert', './save/mami_submission/violence_mmf_transformer', './save/mami_submission/violence_vilbert']\n",
    "files = [mi_file, sh_file, st_file, ob_file, vi_file]\n",
    "\n",
    "for idx in range(len(files)):\n",
    "    \n",
    "    data, ids = concat_inputs(report_dir='', files=files[idx], mode='test') \n",
    "    res = pd.DataFrame(((data.sum(axis=1)/len(data.columns)) > 0.5).astype(int))\n",
    "    \n",
    "    if idx == 0:\n",
    "        submission = res\n",
    "    else:\n",
    "        submission = pd.concat([submission, res], axis=1)\n",
    "\n",
    "out_path = 'answer_ave.txt'\n",
    "submission = pd.concat([pd.DataFrame(ids), submission], axis=1)\n",
    "\n",
    "# # fix misogynous columns\n",
    "# temp = submission[submission.iloc[:,1] == 0]\n",
    "# temp = temp.iloc[:,2:].sum(axis=1) > 1\n",
    "# temp = temp.loc[temp == True].index.to_list()\n",
    "# submission.iloc[temp,1] = 1\n",
    "\n",
    "# # fix other four columns\n",
    "# filter_ = submission.iloc[:,1] == 0\n",
    "# submission[filter_] = submission[filter_].replace(1, 0)\n",
    "submission.to_csv(out_path, header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da35f45a",
   "metadata": {},
   "source": [
    "# Final averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0599faf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>mi</th>\n",
       "      <th>sh</th>\n",
       "      <th>st</th>\n",
       "      <th>ob</th>\n",
       "      <th>vi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15236.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15805.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16254.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16191.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15952.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>15591.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>15049.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>15363.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>15199.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>15853.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           img  mi  sh  st  ob  vi\n",
       "0    15236.jpg   1   0   0   0   0\n",
       "1    15805.jpg   1   0   1   0   0\n",
       "2    16254.jpg   1   0   0   0   0\n",
       "3    16191.jpg   0   0   0   1   0\n",
       "4    15952.jpg   1   0   0   0   0\n",
       "..         ...  ..  ..  ..  ..  ..\n",
       "995  15591.jpg   1   1   0   1   0\n",
       "996  15049.jpg   1   1   0   0   0\n",
       "997  15363.jpg   1   1   1   1   0\n",
       "998  15199.jpg   1   0   0   0   0\n",
       "999  15853.jpg   0   0   0   0   0\n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ave = 'answer_ave.txt'\n",
    "nn = 'answer_nn.txt'\n",
    "mul = 'answer_mul.txt'\n",
    "ave = pd.read_csv(ave, sep='\\t')\n",
    "nn = pd.read_csv(nn, sep='\\t')\n",
    "mul = pd.read_csv(mul, sep='\\t')\n",
    "ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8317d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ave.columns.to_list()\n",
    "columns.remove('img')\n",
    "for col in columns:\n",
    "    ave[col] = ((ave[col] + nn[col] + mul[col]) / 3 > 0.5).astype(int)\n",
    "\n",
    "temp = ave[ave.iloc[:,1] == 0]\n",
    "temp = temp.iloc[:,2:].sum(axis=1) > 1\n",
    "temp = temp.loc[temp == True].index.to_list()\n",
    "ave.iloc[temp,1] = 1\n",
    "\n",
    "filter_ = ave.iloc[:,1] == 0\n",
    "ave[filter_] = ave[filter_].replace(1, 0)\n",
    "ave.to_csv('answer.txt', header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6c23d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>mi</th>\n",
       "      <th>sh</th>\n",
       "      <th>st</th>\n",
       "      <th>ob</th>\n",
       "      <th>vi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15236.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15805.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16254.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16191.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15952.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>15591.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>15049.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>15363.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>15199.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>15853.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           img  mi  sh  st  ob  vi\n",
       "0    15236.jpg   1   0   0   0   0\n",
       "1    15805.jpg   1   1   1   0   0\n",
       "2    16254.jpg   1   0   0   0   0\n",
       "3    16191.jpg   0   0   0   0   0\n",
       "4    15952.jpg   1   0   0   0   0\n",
       "..         ...  ..  ..  ..  ..  ..\n",
       "995  15591.jpg   1   1   1   1   0\n",
       "996  15049.jpg   1   1   0   0   0\n",
       "997  15363.jpg   1   1   1   1   0\n",
       "998  15199.jpg   1   0   0   0   0\n",
       "999  15853.jpg   0   0   0   0   0\n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c42ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmf",
   "language": "python",
   "name": "mmf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
